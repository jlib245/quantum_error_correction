Path to model/logs: Final_Results_QECCT/surface/FFNN_Code_L_3/noise_model_independent/repetition_1/11_11_2025_23_01_01
Namespace(epochs=200, workers=4, lr=0.001, gpus='0', batch_size=128, test_batch_size=512, seed=42, code_type='surface', code_L=3, repetitions=1, noise_type='independent', y_ratio=0.3, N_dec=6, d_model=128, h=16, lambda_loss_ber=0.3, lambda_loss_ler=1.0, lambda_loss_n_pred=0.3, lambda_loss_log_pred=1, no_g=0, no_mask=0, code=<__main__.Code object at 0x751232bde980>, path='Final_Results_QECCT/surface/FFNN_Code_L_3/noise_model_independent/repetition_1/11_11_2025_23_01_01')
사용 가능한 GPU가 없어 CPU를 사용합니다.
PC matrix shape torch.Size([8, 18])
ECC_FFNN(
  (fc1): Linear(in_features=8, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=4, bias=True)
  (activation): Sigmoid()
  (criterion): CrossEntropyLoss()
)
# of Parameters: 1668
Training epoch 1, Batch 500/1000: LR=1.00e-03, Loss=9.13959e-01 LER=3.626e-01
***Loss=9.13959e-01
Training epoch 1, Batch 1000/1000: LR=1.00e-03, Loss=8.06116e-01 LER=2.766e-01
***Loss=8.06116e-01
Epoch 1 Train Time 9.007667064666748s

Model Saved
Training epoch 2, Batch 500/1000: LR=1.00e-03, Loss=6.85940e-01 LER=1.911e-01
***Loss=6.85940e-01
Training epoch 2, Batch 1000/1000: LR=1.00e-03, Loss=6.80323e-01 LER=1.914e-01
***Loss=6.80323e-01
Epoch 2 Train Time 8.048741102218628s

Model Saved
Training epoch 3, Batch 500/1000: LR=1.00e-03, Loss=6.55956e-01 LER=1.900e-01
***Loss=6.55956e-01
Training epoch 3, Batch 1000/1000: LR=1.00e-03, Loss=6.48097e-01 LER=1.889e-01
***Loss=6.48097e-01
Epoch 3 Train Time 8.00227689743042s

Model Saved
Training epoch 4, Batch 500/1000: LR=9.99e-04, Loss=6.15322e-01 LER=1.823e-01
***Loss=6.15322e-01
Training epoch 4, Batch 1000/1000: LR=9.99e-04, Loss=6.02030e-01 LER=1.794e-01
***Loss=6.02030e-01
Epoch 4 Train Time 8.154342412948608s

Model Saved
Training epoch 5, Batch 500/1000: LR=9.99e-04, Loss=5.76271e-01 LER=1.813e-01
***Loss=5.76271e-01
